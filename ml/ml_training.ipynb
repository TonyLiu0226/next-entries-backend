{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "import en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads data from a txt file\n",
    "#file: file to read from. Each line in file must be split into two parts with a specified character char\n",
    "#char: character to split each line with\n",
    "#arr: array to store each line\n",
    "\n",
    "def load_data(file, char, arr):\n",
    "    with open(file) as f:\n",
    "        num = 0\n",
    "        for line in f:\n",
    "            segments = line.split(char)\n",
    "            list = []\n",
    "            list.append(segments[0])\n",
    "            list.append(segments[1].split('\\n')[0])\n",
    "            arr.append(list)\n",
    "            num+=1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training logistic regression model\n",
    "def train_logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    #performs 10-fold cross validation on the training set\n",
    "    lr = LogisticRegression(penalty='l2', tol=0.0001, C=0.1, class_weight=None, \n",
    "                            random_state=123, solver='lbfgs', max_iter=10000, n_jobs=4, multi_class=\"ovr\")\n",
    "    training_score = cross_validate(lr, X_train, y_train, cv=10, return_train_score=True)\n",
    "    return training_score\n",
    "    #using the best performing model, evaluate it on the testing set\n",
    "\n",
    "#training random forest classifier\n",
    "def train_rf(X_train, y_train, X_test, y_test):\n",
    "    #defines our parameter grid\n",
    "    param_grid = {\n",
    "        'n_estimators': [100],\n",
    "        'max_depth': [200]\n",
    "    }\n",
    "    #perform 10-fold nested cross validation, optimizing the parameter max_depth\n",
    "    inner_cv = KFold(n_splits=3, shuffle=True, random_state=123)\n",
    "    outer_cv = KFold(n_splits=10, shuffle=True, random_state=123)\n",
    "\n",
    "    rf = RandomForestClassifier(n_jobs=-1, random_state=123)\n",
    "\n",
    "    outer_validation = GridSearchCV(estimator=rf, param_grid=param_grid, cv=inner_cv, refit=True)\n",
    "    training_score = cross_validate(outer_validation, X_train, y_train, cv=outer_cv, return_train_score=True)\n",
    "    return (training_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "#preprocesses data using sentence transformers\n",
    "#data: the data to process\n",
    "#df: the dataframe to reference (for indexing)\n",
    "def preprocess_data(data, df):\n",
    "    #cleans text by tokenizing and preprocessing it\n",
    "    df[\"tokenized_entries\"] = [tokenize(e) for e in nlp.pipe(df[\"entries\"])]\n",
    "    #uses countvectorizer to get vector representations of our tokens\n",
    "    countvec = CountVectorizer(stop_words=\"english\")\n",
    "    preprocessed_df = countvec.fit_transform(df[\"tokenized_entries\"])\n",
    "    return preprocessed_df\n",
    "\n",
    "def tokenize(text):\n",
    "    new_text = []\n",
    "    #we keep the token if it meets the following criteria:\n",
    "    # length is 2 or longer\n",
    "    # Not a stopword\n",
    "    # Not part of the prohibited POS tags\n",
    "    # Lemmatization\n",
    "    for token in text:\n",
    "        if (token.is_stop != True and len(token) >= 2 and token.pos_ not in [\"PUNCT\", \"PART\", \"ADJ\", \"PRON\", \"DET\", \"ADP\", \"SPACE\", \"SYM\", \"X\"]):\n",
    "            #converts token's lemma to lowercase before appending it\n",
    "            new_text.append(token.lemma_.lower())\n",
    "    final_text = \" \".join(new_text)\n",
    "    return final_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading data\n",
    "train_data = []\n",
    "test_data = []\n",
    "load_data(\"./emotions/train.txt\", ';', train_data)\n",
    "load_data(\"./emotions/val.txt\", ';', train_data)\n",
    "load_data(\"./emotions/test.txt\", \";\", test_data)\n",
    "\n",
    "train_df = pd.DataFrame(data=train_data, columns=[\"entries\", \"emotions\"])\n",
    "test_df = pd.DataFrame(data=test_data, columns=[\"entries\", \"emotions\"])\n",
    "\n",
    "X_train = train_df.drop(\"emotions\", axis=1)\n",
    "X_test = test_df.drop(\"emotions\", axis=1)\n",
    "y_train = train_df[\"emotions\"]\n",
    "y_test = test_df[\"emotions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 entries\n",
       "0                                i didnt feel humiliated\n",
       "1      i can go from feeling so hopeless to so damned...\n",
       "2       im grabbing a minute to post i feel greedy wrong\n",
       "3      i am ever feeling nostalgic about the fireplac...\n",
       "4                                   i am feeling grouchy\n",
       "...                                                  ...\n",
       "17995  im having ssa examination tomorrow in the morn...\n",
       "17996  i constantly worry about their fight against n...\n",
       "17997  i feel its important to share this info for th...\n",
       "17998  i truly feel that if you are passionate enough...\n",
       "17999  i feel like i just wanna buy any cute make up ...\n",
       "\n",
       "[18000 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                entries\n",
       "0     im feeling rather rotten so im not very ambiti...\n",
       "1             im updating my blog because i feel shitty\n",
       "2     i never make her separate from me because i do...\n",
       "3     i left with my bouquet of red and yellow tulip...\n",
       "4       i was feeling a little vain when i did this one\n",
       "...                                                 ...\n",
       "1995  i just keep feeling like someone is being unki...\n",
       "1996  im feeling a little cranky negative after this...\n",
       "1997  i feel that i am useful to my people and that ...\n",
       "1998  im feeling more comfortable with derby i feel ...\n",
       "1999  i feel all weird when i have to meet w people ...\n",
       "\n",
       "[2000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        sadness\n",
       "1        sadness\n",
       "2          anger\n",
       "3           love\n",
       "4          anger\n",
       "          ...   \n",
       "17995    sadness\n",
       "17996        joy\n",
       "17997        joy\n",
       "17998        joy\n",
       "17999        joy\n",
       "Name: emotions, Length: 18000, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       sadness\n",
       "1       sadness\n",
       "2       sadness\n",
       "3           joy\n",
       "4       sadness\n",
       "         ...   \n",
       "1995      anger\n",
       "1996      anger\n",
       "1997        joy\n",
       "1998        joy\n",
       "1999       fear\n",
       "Name: emotions, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = max(len(y_test.unique()), len(y_train.unique()))\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18000x10400 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 104511 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocessing\n",
    "X_train_transformed = preprocess_data(X_train['entries'], train_df)\n",
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x2931 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 11566 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed = preprocess_data(X_test['entries'], test_df)\n",
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([1.67799997, 0.27950048, 0.28399944, 0.30000043, 0.26200008,\n",
       "        0.27550292, 0.26700044, 0.28349948, 0.29400134, 0.29350042]),\n",
       " 'score_time': array([0.00249982, 0.00250125, 0.00249958, 0.0019989 , 0.00250006,\n",
       "        0.00199723, 0.00250053, 0.00199986, 0.00249958, 0.00200057]),\n",
       " 'test_score': array([0.45888889, 0.46333333, 0.45888889, 0.46166667, 0.45555556,\n",
       "        0.44055556, 0.46611111, 0.47388889, 0.46611111, 0.45444444]),\n",
       " 'train_score': array([0.52475309, 0.52512346, 0.52679012, 0.52567901, 0.52549383,\n",
       "        0.52833333, 0.52388889, 0.52475309, 0.52549383, 0.52703704])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model training\n",
    "score1 = train_logistic_regression(X_train_transformed, y_train, X_test_transformed, y_test)\n",
    "score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([109.14550018,  96.20949936,  96.82799959, 109.03499889,\n",
       "         95.68600035,  95.66199946, 108.88549876, 107.94100022,\n",
       "        108.81449962, 108.42549992]),\n",
       " 'score_time': array([0.16649985, 0.07350016, 0.07500076, 0.15700054, 0.08249903,\n",
       "        0.08350039, 0.17850351, 0.15199947, 0.15300035, 0.1570003 ]),\n",
       " 'test_score': array([0.45222222, 0.46222222, 0.46722222, 0.45777778, 0.46944444,\n",
       "        0.45888889, 0.44777778, 0.47722222, 0.45722222, 0.46055556]),\n",
       " 'train_score': array([0.7612963 , 0.75222222, 0.75648148, 0.76049383, 0.76024691,\n",
       "        0.7604321 , 0.75660494, 0.75592593, 0.75753086, 0.75728395])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score2 = train_rf(X_train_transformed, y_train, X_test_transformed, y_test)\n",
    "score2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpsc330",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
